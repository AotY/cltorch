#include "THClApply.h"

// Implementation of copyIgnoringOverlaps, defined after pointwiseApply2.
void THClTensor_copyIgnoringOverlaps(THClState* state,
                                       THClTensor* dst,
                                       THClTensor* src) {
  THClTensor_pointwiseApply2(state, dst, src, CopyOp(),
                               ReadOnly, // ignore overwrites
                               ReadOnly);
}

std::string getApplyDv2_template() {
    // [[[cog
    // import stringify
    // stringify.write_kernel( "kernel", "THClApplyDv2.cl" )
    // ]]]
    // generated using cog, from THClApplyDv2.cl:
    const char * kernelSource =  
    "// OpenCL kernels....\n" 
    "\n" 
    "// expected templated values:\n" 
    "// dims (vector of unique dimension values)\n" 
    "// operation\n" 
    "// dim1\n" 
    "// dim2\n" 
    "// dim3\n" 
    "// ... dimD\n" 
    "// num_input_tensors\n" 
    "// include_scalar_input\n" 
    "//\n" 
    "// maybe should add:\n" 
    "// IndexType (hardcoded to int for now)\n" 
    "// MAX_CUTORCH_DIMS (hardcoded to 25 for now)\n" 
    "\n" 
    "// (Ported from cutorch's THCApply.cuh)\n" 
    "\n" 
    "// Maximum number of dimensions allowed for cutorch\n" 
    "// #define MAX_CUTORCH_DIMS 25\n" 
    "\n" 
    "// Enum that indicates whether tensor arguments are read/write or\n" 
    "// read-only\n" 
    "//enum TensorArgType { ReadWrite, ReadOnly };\n" 
    "\n" 
    "// kernel argument that defines tensor layout\n" 
    "typedef struct TensorInfoCl {\n" 
    "  // Extracts size/stride information for the kernel.\n" 
    "  // Successive dimensions can be collapsed if the size/strides match\n" 
    "  // up and thus there are no holes between the dimensions. This is used\n" 
    "  // to reduce the complexity of the problem.\n" 
    "  // The optional `reduceDim` indicates a reduction dimension for the\n" 
    "  // given tensor, so that the output size for this dimension will be 1.\n" 
    "\n" 
    "  int sizes[{{MAX_CLTORCH_DIMS}}];\n" 
    "  int strides[{{MAX_CLTORCH_DIMS}}];\n" 
    "  int offset;\n" 
    "  int dims;\n" 
    "} TensorInfoCl;\n" 
    "// Contiguous tensors of more than one dimension are collapsed down\n" 
    "// to one tensor\n" 
    "bool TensorInfo_isContiguous( TensorInfoCl tensorInfo ) {\n" 
    "    return (tensorInfo.dims == 1 && tensorInfo.strides[0] == 1);\n" 
    "}\n" 
    "\n" 
    "{%\n" 
    " total_opsize = num_tensors\n" 
    " if include_scalar_input then\n" 
    "      total_opsize = total_opsize + 1\n" 
    "   end\n" 
    " %}\n" 
    "\n" 
    "void op( global float *out\n" 
    "  {% for i=1,(num_tensors-1) do %}\n" 
    "  , global float *in{{i}}\n" 
    "  {% end %}\n" 
    "  {% for i=1,(num_scalars) do %}\n" 
    "  , float val{{i}}\n" 
    "  {% end %}\n" 
    ") {\n" 
    "    {{operation}};\n" 
    "}\n" 
    "\n" 
    "// Translate a linear index for the apply to a float* offset;\n" 
    "// specialized on `Dims` to reduce nvcc compilation time\n" 
    "{% for _,dim in ipairs(dims) do %}\n" 
    "int IndexToOffset_{{1000 + dim}}_get( int linearId, TensorInfoCl info) {\n" 
    "  int offset = 0;\n" 
    "\n" 
    "  // Use static dims\n" 
    "  for (int i = {{dim}} - 1; i >= 0; --i) {\n" 
    "    int curDimIndex = linearId % info.sizes[i];\n" 
    "    int curDimOffset = curDimIndex * info.strides[i];\n" 
    "    offset += curDimOffset;\n" 
    "\n" 
    "    if (i > 0) {\n" 
    "      linearId /= info.sizes[i];\n" 
    "    }\n" 
    "  }\n" 
    "\n" 
    "  return offset;\n" 
    "}\n" 
    "{% end %}\n" 
    "\n" 
    "int IndexToOffset_998_get(int linearId, const TensorInfoCl info) {\n" 
    "    return linearId;\n" 
    "}\n" 
    "\n" 
    "int IndexToOffset_999_get(int linearId, const TensorInfoCl info) {\n" 
    "  int offset = 0;\n" 
    "\n" 
    "  // Use dynamic dims\n" 
    "  for (int i = info.dims - 1; i >= 0; --i) {\n" 
    "    int curDimIndex = linearId % info.sizes[i];\n" 
    "    int curDimOffset = curDimIndex * info.strides[i];\n" 
    "    offset += curDimOffset;\n" 
    "\n" 
    "    linearId /= info.sizes[i];\n" 
    "  }\n" 
    "\n" 
    "  return offset;\n" 
    "}\n" 
    "\n" 
    "kernel void\n" 
    "THClTensor_pointwiseApplyD(\n" 
    "   {% for input_idx=1,num_tensors do %}\n" 
    "    global TensorInfoCl *info_{{input_idx}},\n" 
    "    global float*data_{{input_idx}},\n" 
    "   {% end %}\n" 
    "   {% for i=1,num_scalars do %}\n" 
    "   float val{{i}},\n" 
    "   {% end %}\n" 
    "   int totalElements) {\n" 
    "  for (int linearIndex = get_global_id(0);\n" 
    "       linearIndex < totalElements;\n" 
    "       linearIndex += get_global_size(0) /* ? */ ) {\n" 
    "    {% for input_idx=1,num_tensors do %}\n" 
    "    // Convert `linearIndex` into an offset of `a`\n" 
    "    const int offset{{input_idx}} =\n" 
    "      IndexToOffset_{{1000+loadstring('return dim' .. input_idx)()}}_get(linearIndex, info_{{input_idx}}[0]);\n" 
    "    {% end %}\n" 
    "\n" 
    "    op(\n" 
    "      {% for input_idx=1,num_tensors do %}\n" 
    "         {% if input_idx > 1 then %} , {% end %}\n" 
    "         &(data_{{input_idx}}[offset{{input_idx}} + info_{{input_idx}}->offset])\n" 
    "      {% end %}\n" 
    "      {% for i=1,num_scalars do %}\n" 
    "      , val{{i}}\n" 
    "      {% end %}\n" 
    "    );\n" 
    "  }\n" 
    "}\n" 
    "\n" 
    "";
    // [[[end]]]
    return kernelSource;
}

